{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula 1 Race Predictor\n",
    "### CP468 Final Project\n",
    "### By: Robert Mazza and Ronny Yehia\n",
    "\n",
    "<img src=\"./Images/F1-logo.png\" alt=\"F1 Logo\" width=\"50%\"/>\n",
    "\n",
    "Data set used: https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020\n",
    "\n",
    "See the README for more contextual information around this project.\n",
    "\n",
    "# Data Collection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing the datasets\n",
    "results_df = pd.read_csv('./data/results.csv')\n",
    "status_df = pd.read_csv('./data/status.csv')\n",
    "drivers_df = pd.read_csv('./data/drivers.csv')\n",
    "races_df = pd.read_csv('./data/races.csv')\n",
    "constructor_df = pd.read_csv('./data/constructors.csv')\n",
    "driver_standings_df = pd.read_csv('./data/driver_standings.csv')\n",
    "quali_df = pd.read_csv('./data/qualifying.csv')\n",
    "constructor_standings_df = pd.read_csv('./data/constructor_standings.csv')\n",
    "pd.get_option(\"display.max_columns\",None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing the necessary data sets along with the necessary packages to correctly assess the data. The above data sets include races, drivers, standings, results, qualifications for certain races, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualifying\n",
    "The rules of qualifying has changed over the years regarding how many sessions there are, and the time they last. The one variable that has never changed is how the fastest lap each driver sets counts towards where they start the race. So for this reason I will only be focusing on the starting position of each driver since that is the result of their qualifying performance.\n",
    "\n",
    "<img src=\"./Images/starting-grid.jpg\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop driver number column as it is not needed since we have the driver id\n",
    "quali_df.drop(['number'], axis=1, inplace=True)\n",
    "\n",
    "# drop Q1, Q2, Q3 columns as we only care about starting position\n",
    "quali_df.drop(['q1','q2','q3'], axis=1, inplace=True)\n",
    "\n",
    "# check for null values\n",
    "print(quali_df.isna().sum())\n",
    "# drop all rows that have NULL values\n",
    "quali_df.dropna(inplace = True)\n",
    "\n",
    "print((quali_df['qualifyId'] >= 0).all())\n",
    "print((quali_df['raceId'] >= 0).all())\n",
    "print((quali_df['driverId'] >= 0).all())\n",
    "print((quali_df['constructorId'] >= 0).all())\n",
    "print((quali_df['position'] >= 0).all())\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to us even being able to predict which drivers are going to place where, we must see who qualifies. Starting position is based on the time set on the qualifying laps before the actual competitive race has begun. From there we can determine where each driver is starting, which will impact their chances in the race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Races\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the time column as it is not needed\n",
    "races_df.drop(['time'], axis=1, inplace=True)\n",
    "\n",
    "# drop the wikipedia URLs column\n",
    "races_df.drop(['url'], axis=1, inplace=True)\n",
    "\n",
    "# check for null values\n",
    "print(races_df.isna().sum())\n",
    "\n",
    "races_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the sums above we have no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping unnecessary values that wouldn't be used to determine placement in the actual race, we double check for null values to ensure there are none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "results_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "results_df.drop(['time', 'number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both \"position\" and \"fastestLapSpeed\" are not numerical, which is fixed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(results_df['fastestLapSpeed'], errors='coerce')\n",
    "pd.to_numeric(results_df['position'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(driver_standings_df.isna().sum())\n",
    "\n",
    "driver_standings_df.info()\n",
    "\n",
    "print(\"Checking if all values are equal or greater than zero\")\n",
    "# check if each coloumn that is int64 has a value greater or equal of zero\n",
    "# True = good, False = bad\n",
    "print((driver_standings_df['driverStandingsId'] >= 0).all())\n",
    "print((driver_standings_df['raceId'] >= 0).all())\n",
    "print((driver_standings_df['driverId'] >= 0).all())\n",
    "print((driver_standings_df['points'] >= 0).all())\n",
    "print((driver_standings_df['position'] >= 0).all())\n",
    "print((driver_standings_df['wins'] >= 0).all())\n",
    "\n",
    "# dropping unneeded columns\n",
    "driver_standings_df.drop(['driverStandingsId', 'positionText' ], axis=1, inplace=True)\n",
    "# renaming the columns for easier understanding\n",
    "driver_standings_df.rename(columns = {'wins':'driver_standings_race_wins', 'points':'driver_standings_points', 'position': 'driver_standings_position'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As presumed, the driver standings are determined by numerous factors. All the values above that are checked whether they are larger or equal to 0 play a role in determining standings, points, position, wins, etc. All these values are taken into account when attempting to determine who is likely to place where in the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_standings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructors Standings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula 1 didn't have a Constructors Champiionship till 1958, before that the only championship was the Drivers Championship. So we will not have values in this dataset that represent any races before 1958."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(constructor_standings_df.isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "print(\"Checking if all values are equal or greater than zero\")\n",
    "# check if each coloumn that is int64 has a value greater or equal of zero\n",
    "# True = good, False = bad\n",
    "print((constructor_standings_df['raceId'] >= 0).all())\n",
    "print((constructor_standings_df['constructorId'] >= 0).all())\n",
    "print((constructor_standings_df['points'] >= 0).all())\n",
    "print((constructor_standings_df['position'] >= 0).all())\n",
    "print((constructor_standings_df['wins'] >= 0).all())\n",
    "\n",
    "# dropping useless columns\n",
    "constructor_standings_df.drop(['constructorStandingsId', 'positionText'], axis=1, inplace=True)\n",
    "# rename columns to avoid confusion with other dataframes\n",
    "constructor_standings_df.rename(columns = {'wins':'constructor_race_wins', 'points':'constructor_points', 'position': 'constructor_position'}, inplace = True)\n",
    "\n",
    "constructor_standings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_standings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There have been many different constructors ever the years, not all still race in current seasons but there are still a few that have never left F1, such as Ferrari, Williams, and McLaren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(constructor_df.isna().sum())\n",
    "\n",
    "# drop URL column\n",
    "constructor_df.drop(['url'], axis=1, inplace=True)\n",
    "# drop constructor natonality column as it is not needed\n",
    "constructor_df.drop(['nationality'], axis=1, inplace=True)\n",
    "\n",
    "constructor_df.info()\n",
    "\n",
    "print(\"Checking if all values are equal or greater than zero\")\n",
    "# check if each coloumn that has a value greater or equal of zero or not ''\n",
    "# True = good, False = bad\n",
    "print((constructor_df['name'] != '').all())\n",
    "print((constructor_df['constructorRef'] != '').all())\n",
    "print((constructor_df['constructorId'] >= 0).all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A majority of the above code is testing to ensure that the data is usable, which is why we are checking for 0 values or NULL values in most of them. Values with 0 or NULL cannot be used in predicting placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(drivers_df.isna().sum())\n",
    "# drop URL column\n",
    "drivers_df.drop(['url'], axis=1, inplace=True)\n",
    "# drop constructor natonality column as it is not needed\n",
    "drivers_df.drop(['nationality'], axis=1, inplace=True)\n",
    "# drop driver number column, we will refer to each driver by their last name\n",
    "drivers_df.drop(['number'], axis=1, inplace=True )\n",
    "\n",
    "drivers_df.info()\n",
    "\n",
    "print(\"Checking if all values are equal or greater than zero\")\n",
    "# check if each coloumn that has a value greater or equal of zero or not ''\n",
    "# True = good, False = bad\n",
    "print((drivers_df['driverRef'] != '').all())\n",
    "print((drivers_df['code'] != '').all())\n",
    "print((drivers_df['forename'] != '').all())\n",
    "print((drivers_df['surname'] != '').all())\n",
    "print((drivers_df['driverId'] >= 0).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status\n",
    "Describes the status of the car in respect to finishing the race. If the car did not finish the race then it will have a \"Status\" that gives some more detail to why the car did not finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "print(status_df.isna().sum())\n",
    "\n",
    "status_df.info()\n",
    "\n",
    "print((status_df['statusId'] >= 0).all())\n",
    "print((status_df['status'] != '').all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging all the dataframes into a single comprehensive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all seperate dataframe into single dataframe as df\n",
    "\n",
    "df0 = pd.merge(results_df, constructor_standings_df, on = ['raceId', 'constructorId'])\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.merge(df0, races_df, on ='raceId')\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.merge(df1, drivers_df, on = 'driverId')\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3 = pd.merge(df2, constructor_df, on ='constructorId')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(df3, status_df, on ='statusId')\n",
    "pd.get_option(\"display.max_columns\",None)\n",
    "\n",
    "df.drop(['statusId', 'rank','fastestLapTime', 'constructorId', 'constructorRef', 'driverRef'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = {'milliseconds':'timetaken_in_millisec','fastestLapSpeed':'max_speed',\n",
    " 'name_x':'grand_prix','number_y':'driver_num','code':'driver_code','name_y':'constructor_name',\n",
    " 'raceId_x':'racerId','points_x':'points'}\n",
    "\n",
    "df.rename(columns=col_name, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the forename and surname of the driver into a single column\n",
    "df['driver_name'] = df['forename'] + ' ' + df['surname']\n",
    "df  = df.drop(['forename', 'surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date and dob columns are being stored as an Object, so it will be changed to Date object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# getting each driver's age and storing it in a new column 'age'\n",
    "\n",
    "dates = datetime.today()-df['dob']\n",
    "age = dates.dt.days/365\n",
    "# round them up if they are close to their next birthday than their last\n",
    "df['age'] = round(age) \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.drop(['dob'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatype\n",
    "\n",
    "l = ['timetaken_in_millisec','fastestLap','max_speed']\n",
    "for i in l:\n",
    "    df[i] = pd.to_numeric(df[i],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values\n",
    "df[['fastestLap']] = df[['fastestLap']].fillna(0)\n",
    "df['timetaken_in_millisec'] = df['timetaken_in_millisec'].fillna(df['timetaken_in_millisec'].mean())\n",
    "df['max_speed']= df['max_speed'].fillna(df['max_speed'].mean())\n",
    "df.isnull().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat = []\n",
    "num = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == 'O':\n",
    "        cat.append(i)\n",
    "    else:\n",
    "        num.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploritory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualifying Advantage?\n",
    "Everyone knows that qualifying is a big deal, but how important is a high starting position? More specifically, how important is qualifying first? This changes depending on the circuit as some circuits are narrow and hard to perform overtakes such as Monaco where qualifying position is almost more important than the race itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# circuitId: 6 is monaco\n",
    "x = df[(df.circuitId == 6) & (df.status == 'Finished')].grid\n",
    "\n",
    "# using positionOrder here because it takes into account finishing position of DNFs\n",
    "y = df[(df.circuitId == 6) & (df.status == 'Finished')].positionOrder\n",
    "\n",
    "plt.scatter(x,y)\n",
    "\n",
    "b, a = np.polyfit(x, y, deg=1)\n",
    "\n",
    "print(\"Correlation:\", x.corr(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a moderate positive correlation between a drivers starting position and finishing position at Monaco. This is most likely due to all the other variables of racing like crashes and pit strategies that mix up the grid from qualifying order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Important Is Starting From 1st?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[(df.grid == 1) & (df.status == 'Finished')].positionOrder\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above and a mean finishing position of 1.8 if the driver started from 1st, we can make the conclusion that qualifying position is vital for winning a race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grand Prix Locations\n",
    "Formula 1 has been running since the 1950s, in this time the sport has grown from a total of 7 Grand Proxs in a championship to 19 - 20 Grand Prixs located all around the world. Below is a map showing every circuit F1 has visited since the 1950s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "circuits_df = pd.read_csv('./data/circuits.csv')\n",
    "\n",
    "coords = []\n",
    "\n",
    "# plotting all circuits F1 has raced at in the world\n",
    "for lat,lng in zip(circuits_df['lat'],circuits_df['lng']):\n",
    "    coords.append([lat,lng])\n",
    "maps = folium.Map(zoom_start=2,tiles='OpenStreetMap')  #map_types (Stamen Terrain, Stamen Toner, Mapbox Bright, cartodbpositron)\n",
    "for i,j in zip(coords,circuits_df.name):\n",
    "    marker = folium.Circle(\n",
    "        location=i,\n",
    "        radius=1000,\n",
    "        popup=\"<strong>{0}</strong>\".format(j))  #strong is used to bold the font (optional)\n",
    "    marker.add_to(maps)\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the data into and x and y set. x will contain all our data used to predict y, which is the finishing position. We are only going to look at races after 1990 as there are major gaps in the data before then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "Splitting the data so that training is F1 seasons after 1990 and before 2021 (exlusive). We will test the data on the 2021 season. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter data for only Finished results after 1990 and before 2020\n",
    "\n",
    "x_train = df[(df.status == 'Finished') & (df.year > 1990) & (df.year < 2021)]\n",
    "\n",
    "# only keep numerical columns\n",
    "x_train = x_train.select_dtypes(['number'])\n",
    "\n",
    "x_train.drop(['resultId', 'positionOrder', 'points'], axis=1, inplace=True)\n",
    "\n",
    "x_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data input with be evaluated race data between 1990 - 2021 (exclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df[(df.status == 'Finished') & (df.year == 2021)]\n",
    "x_test = x_test.select_dtypes(['number'])\n",
    "\n",
    "x_test.drop(['resultId', 'positionOrder', 'points'], axis=1, inplace=True)\n",
    "\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data output with be evaluated using race position data between 1990 - 2021 (exclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[(df.status == 'Finished') & (df.year > 1990) & (df.year < 2021)].positionOrder\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the main dataframe to create y_test dataframe containing all the finishing results from the 2021 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df[(df.status == 'Finished') & (df.year == 2021)].positionOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling our data for use in our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns = x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom function to score the regression based on if the model was able to predict the race winner correctly or not. Purely focused on the race winner and not other positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_regression(model):\n",
    "    score = 0\n",
    "    # test the model on the test set, which is the 2021 season\n",
    "    for circuit in df[df.year == 2021]['round'].unique():\n",
    "        test = df[(df['year'] == 2021) & (df['round'] == circuit)]\n",
    "        x_test = test.select_dtypes(['number'])\n",
    "\n",
    "        x_test.drop(['resultId', 'positionOrder', 'points'], axis=1, inplace=True)\n",
    "        y_test = test.positionOrder\n",
    "\n",
    "        # scaling the data\n",
    "        x_test = pd.DataFrame(scaler.transform(x_test), columns = x_test.columns)\n",
    "\n",
    "        # make predictions dataframe\n",
    "        prediction_df = pd.DataFrame(model.predict(x_test), columns = ['results'])\n",
    "        prediction_df['positionOrder'] = y_test.reset_index(drop = True)\n",
    "        prediction_df['actual'] = prediction_df.positionOrder.map(lambda x: 1 if x == 1 else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)\n",
    "        prediction_df['predicted'] = prediction_df.index\n",
    "        prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "        print(\"Round\", circuit)\n",
    "        \n",
    "        score += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "\n",
    "    model_score = score / df[df.year == 2021]['round'].unique().max()\n",
    "    return model_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crating a dictionary that will allow us to compare results from all our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict ={'model':[],\n",
    "                  'params': [],\n",
    "                  'score': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression model. Testing both with and without \"fit_intercept\" parameters. This model is not going to be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "params={'fit_intercept': ['True', 'False']}\n",
    "\n",
    "for fit_intercept in params['fit_intercept']:\n",
    "    model_params = (fit_intercept)\n",
    "    model = LinearRegression(fit_intercept = fit_intercept)\n",
    "    model.fit(x_train, y_train)\n",
    "            \n",
    "    model_score = score_regression(model)\n",
    "            \n",
    "    comparison_dict['model'].append('linear_regression')\n",
    "    comparison_dict['params'].append(model_params)\n",
    "    comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(comparison_dict).groupby('model')['score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "\n",
    "params={'hidden_layer_sizes': [(80,20,40,5), (75,30,50,10,3)], \n",
    "        'activation': ['identity', 'relu','logistic', 'tanh',], \n",
    "        'solver': ['lbfgs','sgd', 'adam'], \n",
    "        'alpha': np.logspace(-4,1,20)} \n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha )\n",
    "                model = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                      activation = activation, solver = solver,\n",
    "                                       alpha = alpha, random_state = 1, max_iter = 1000)\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                model_score = score_regression(model)\n",
    "\n",
    "                comparison_dict['model'].append('nn_regressor')\n",
    "                comparison_dict['params'].append(model_params)\n",
    "                comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(comparison_dict).groupby('model')['score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(comparison_dict).groupby('model')['params'].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "797a9957bc75de0d212fc45004d953b4066e1aaa9007c0e6e0eb4f0a99edd7b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
